/**
 * 第2章クイズデータ - 機械学習の手法
 */
export const chapter2Quiz = [
    {
        id: 'ch2_q1',
        question: '教師あり学習の特徴として正しいものは？',
        options: [
            '正解ラベルなしでデータの構造を発見する',
            '正解ラベル付きのデータから学習する',
            '報酬を最大化するように行動を学習する',
            'ルールを人間が定義する'
        ],
        correctIndex: 1,
        explanation: '教師あり学習は、入力と正解（ラベル）のペアから、入力から正解を予測するモデルを学習します。',
        keywords: ['教師あり学習', '正解ラベル', '分類', '回帰'],
        hint: '「教師」という名前が示すように、正解を教えてもらいながら学ぶ手法です。'
    },
    {
        id: 'ch2_q2',
        question: '教師あり学習の「分類」と「回帰」の違いとして正しいものは？',
        options: [
            '分類は連続値を予測し、回帰はカテゴリを予測する',
            '分類はカテゴリを予測し、回帰は連続値を予測する',
            '分類は画像に使い、回帰はテキストに使う',
            'どちらも同じ結果を出す'
        ],
        correctIndex: 1,
        explanation: '分類は離散的なカテゴリ（クラス）を予測し、回帰は連続的な数値を予測します。',
        keywords: ['分類', '回帰', 'カテゴリ', '連続値'],
        hint: '予測する値が「種類」なのか「数値」なのかで使い分けます。'
    },
    {
        id: 'ch2_q3',
        question: '決定木の利点として最も適切なものは？',
        options: [
            '計算が非常に高速',
            '結果の解釈がしやすい',
            '大規模データに強い',
            '過学習が起きにくい'
        ],
        correctIndex: 1,
        explanation: '決定木は条件分岐で表現されるため、人間にとって理解しやすい説明が可能です。',
        keywords: ['決定木', '解釈性', '条件分岐'],
        hint: '木構造で判断過程が視覚化できる点がメリットです。'
    },
    {
        id: 'ch2_q4',
        question: 'サポートベクターマシン（SVM）の基本的な考え方は？',
        options: [
            '最も近い点を基準に分類する',
            'クラス間のマージンを最大化する境界を見つける',
            'データをクラスタに分ける',
            '確率的に分類する'
        ],
        correctIndex: 1,
        explanation: 'SVMは、2つのクラスを分ける境界線と各クラスの最も近いデータ点との距離（マージン）を最大化します。',
        keywords: ['SVM', 'マージン最大化', '境界'],
        hint: 'クラス間の「余裕」を最大限確保する考え方です。'
    },
    {
        id: 'ch2_q5',
        question: 'k-NN（k近傍法）の分類方法として正しいものは？',
        options: [
            '木構造で判断する',
            '最も近いk個のデータの多数決で分類する',
            '確率分布を推定して分類する',
            'ニューラルネットワークを使用する'
        ],
        correctIndex: 1,
        explanation: 'k-NNは、新しいデータに最も近いk個の訓練データを見つけ、その多数決でクラスを決定します。',
        keywords: ['k-NN', 'k近傍法', '多数決', '距離'],
        hint: '近所の住民に聞いて多数決で決めるイメージです。'
    },
    {
        id: 'ch2_q6',
        question: '教師なし学習の代表的なタスクは？',
        options: [
            '画像分類',
            'クラスタリング',
            'スパム判定',
            '株価予測'
        ],
        correctIndex: 1,
        explanation: '教師なし学習はラベルなしデータから構造を発見します。クラスタリングは類似データをグループ化する代表的なタスクです。',
        keywords: ['教師なし学習', 'クラスタリング', 'ラベルなし'],
        hint: '正解がない状態で、データ自体から何かを見つけ出すタスクです。'
    },
    {
        id: 'ch2_q7',
        question: 'k-means法について正しい説明は？',
        options: [
            'k個の最近傍点で分類する',
            'データをk個のクラスタに分割する',
            'k層のニューラルネットワークを使う',
            'k回繰り返し学習する'
        ],
        correctIndex: 1,
        explanation: 'k-means法は、データをk個のクラスタに分割し、各クラスタの中心との距離を最小化するクラスタリング手法です。',
        keywords: ['k-means', 'クラスタリング', 'クラスタ中心'],
        hint: 'クラスタの「数」を事前に決めて分割する手法です。'
    },
    {
        id: 'ch2_q8',
        question: '主成分分析（PCA）の目的として最も適切なものは？',
        options: [
            'データを分類する',
            'データの次元を削減する',
            'データを生成する',
            'データを暗号化する'
        ],
        correctIndex: 1,
        explanation: 'PCAは高次元データを、情報をなるべく保持しながら低次元に圧縮（次元削減）する手法です。',
        keywords: ['PCA', '主成分分析', '次元削減'],
        hint: '多くの特徴量を、より少ない数に圧縮したい時に使います。'
    },
    {
        id: 'ch2_q9',
        question: '強化学習の基本的な仕組みとして正しいものは？',
        options: [
            '正解ラベルを使って学習する',
            '報酬を最大化するように試行錯誤で学習する',
            'データの構造を発見する',
            '人間がルールを定義する'
        ],
        correctIndex: 1,
        explanation: '強化学習は、エージェントが環境と相互作用しながら、得られる報酬を最大化する行動方針を学習します。',
        keywords: ['強化学習', '報酬', 'エージェント', '環境'],
        hint: 'ゲームをプレイして高スコアを目指すイメージです。'
    },
    {
        id: 'ch2_q10',
        question: '過学習（オーバーフィッティング）とは？',
        options: [
            '学習データが多すぎること',
            '訓練データに過度に適合し、未知データへの性能が低下すること',
            '計算時間が長すぎること',
            'モデルが単純すぎること'
        ],
        correctIndex: 1,
        explanation: '過学習は、訓練データに過度に最適化され、その結果、未知のデータに対する汎化性能が低下する現象です。',
        keywords: ['過学習', 'オーバーフィッティング', '汎化性能'],
        hint: '暗記しすぎて応用が利かなくなる状態に似ています。'
    },
    {
        id: 'ch2_q11',
        question: '交差検証（クロスバリデーション）の目的は？',
        options: [
            'データを増やす',
            'モデルの汎化性能を適切に評価する',
            '学習速度を上げる',
            '特徴量を選択する'
        ],
        correctIndex: 1,
        explanation: '交差検証は、データを複数に分割して検証を繰り返すことで、モデルの汎化性能をより正確に評価します。',
        keywords: ['交差検証', 'クロスバリデーション', 'K-fold'],
        hint: 'データを有効活用して、信頼性の高い評価を行う手法です。'
    },
    {
        id: 'ch2_q12',
        question: '混同行列（Confusion Matrix）に含まれないものは？',
        options: [
            '真陽性（TP）',
            '偽陽性（FP）',
            '真陰性（TN）',
            '学習率（LR）'
        ],
        correctIndex: 3,
        explanation: '混同行列はTP（真陽性）、FP（偽陽性）、TN（真陰性）、FN（偽陰性）の4つで構成されます。学習率は最適化のパラメータです。',
        keywords: ['混同行列', 'TP', 'FP', 'TN', 'FN'],
        hint: '分類結果を「正解/不正解」×「予測のYes/No」で分類した表です。'
    },
    {
        id: 'ch2_q13',
        question: '適合率（Precision）の計算式として正しいものは？',
        options: [
            'TP / (TP + FN)',
            'TP / (TP + FP)',
            '(TP + TN) / 全データ数',
            'TN / (TN + FP)'
        ],
        correctIndex: 1,
        explanation: '適合率は「陽性と予測したもののうち、実際に陽性だった割合」で、TP / (TP + FP) です。',
        keywords: ['適合率', 'Precision', 'TP', 'FP'],
        hint: '「陽性」と予測した中に、どれだけ本当の陽性が含まれているか、を測る指標です。'
    },
    {
        id: 'ch2_q14',
        question: '再現率（Recall）が重要視されるケースは？',
        options: [
            'スパムメールの誤検知を減らしたい時',
            '病気の見逃しを減らしたい時',
            '計算コストを削減したい時',
            'モデルを軽量化したい時'
        ],
        correctIndex: 1,
        explanation: '再現率は「実際の陽性をどれだけ漏れなく検出できたか」を測るため、見逃しが許されない場面で重視されます。',
        keywords: ['再現率', 'Recall', '見逃し'],
        hint: '「漏れ」が許されない状況で重要になる指標です。'
    },
    {
        id: 'ch2_q15',
        question: 'F値（F1スコア）とは何か？',
        options: [
            '適合率と再現率の単純平均',
            '適合率と再現率の調和平均',
            '正解率の別名',
            '損失関数の一種'
        ],
        correctIndex: 1,
        explanation: 'F値は適合率と再現率の調和平均で、両者のバランスを評価する指標です。',
        keywords: ['F値', 'F1スコア', '調和平均'],
        hint: '2つの指標をバランスよく考慮するための計算方法が使われています。'
    },
    {
        id: 'ch2_q16',
        question: 'ROC曲線のAUCが1に近いほど何を意味するか？',
        options: [
            'モデルの性能が悪い',
            'モデルの性能が良い',
            'データが足りない',
            '過学習している'
        ],
        correctIndex: 1,
        explanation: 'AUC（Area Under Curve）は0から1の値を取り、1に近いほど分類性能が高いことを示します。',
        keywords: ['ROC曲線', 'AUC', '分類性能'],
        hint: '曲線の下の「面積」が大きいほど良いモデルです。'
    },
    {
        id: 'ch2_q17',
        question: 'アンサンブル学習の代表的な手法は？',
        options: [
            '単純パーセプトロン',
            'ランダムフォレスト',
            'ロジスティック回帰',
            'k近傍法'
        ],
        correctIndex: 1,
        explanation: 'ランダムフォレストは複数の決定木を組み合わせるアンサンブル学習の代表的な手法です。',
        keywords: ['アンサンブル学習', 'ランダムフォレスト', 'バギング'],
        hint: '複数のモデルを組み合わせて精度を向上させる手法です。'
    },
    {
        id: 'ch2_q18',
        question: '勾配ブースティングの特徴として正しいものは？',
        options: [
            '独立した複数モデルを並列に学習',
            '前のモデルの誤差を次のモデルで補正しながら学習',
            'モデルを間引いて軽量化',
            'データを圧縮して学習'
        ],
        correctIndex: 1,
        explanation: '勾配ブースティングは、前のモデルの残差（誤差）を次のモデルで予測し、順次改善していく手法です。',
        keywords: ['勾配ブースティング', 'XGBoost', 'LightGBM', '残差'],
        hint: '前の失敗を次のモデルがカバーする、チームワーク的なアプローチです。'
    }
];
